{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Binary Classification Model: Total Trial Fund Usage Prediction\n",
        "\n",
        "This notebook builds a Logistic Regression model to predict `总体验金使用` (1 = Yes, 0 = No)."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Step 1: Import Libraries"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {},
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.metrics import accuracy_score, f1_score, roc_auc_score, roc_curve\n",
        "from sklearn.compose import ColumnTransformer\n",
        "from sklearn.pipeline import Pipeline\n",
        "from category_encoders import TargetEncoder\n",
        "import joblib\n",
        "import warnings\n",
        "from pathlib import Path\n",
        "from custom_transformers import (\n",
        "    NumericalImputer, \n",
        "    CategoricalImputer, \n",
        "    StringImputer, \n",
        "    CompletePipeline\n",
        ")\n",
        "warnings.filterwarnings('ignore')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Step 2: Load Data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Loading data from: dataset.xlsx\n",
            "\n",
            "Dataset shape: (8585, 30)\n",
            "\n",
            "Column names: ['user_id', 'partner', 'staff', 'nationality', 'VIP_level', 'spot_level', 'asset_level', '昨日账户余额', '新老用户', '是否kyc', 'ARPU30', 'ARPU7', 'ARPU14', '是否为混合交易用户', '当日合约交易量', '当日合约交易笔数', '当日充值金额', '总合约交易量', '总体验金发放', '合约交易频率', '筛选交易日前7日日均交易笔数', '筛选交易日前7日每笔持仓时间', '筛选交易日前7日平均杠杆倍数', '过去30天平均杠杆值', '当日净充提金额', '是否意向流失', '用户分层', '用户活跃等级', 'user_tag', '总体验金使用']\n",
            "\n",
            "First few rows:\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>user_id</th>\n",
              "      <th>partner</th>\n",
              "      <th>staff</th>\n",
              "      <th>nationality</th>\n",
              "      <th>VIP_level</th>\n",
              "      <th>spot_level</th>\n",
              "      <th>asset_level</th>\n",
              "      <th>昨日账户余额</th>\n",
              "      <th>新老用户</th>\n",
              "      <th>是否kyc</th>\n",
              "      <th>...</th>\n",
              "      <th>筛选交易日前7日日均交易笔数</th>\n",
              "      <th>筛选交易日前7日每笔持仓时间</th>\n",
              "      <th>筛选交易日前7日平均杠杆倍数</th>\n",
              "      <th>过去30天平均杠杆值</th>\n",
              "      <th>当日净充提金额</th>\n",
              "      <th>是否意向流失</th>\n",
              "      <th>用户分层</th>\n",
              "      <th>用户活跃等级</th>\n",
              "      <th>user_tag</th>\n",
              "      <th>总体验金使用</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1003380027</td>\n",
              "      <td>官网</td>\n",
              "      <td>官网</td>\n",
              "      <td>俄罗斯</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>36.0</td>\n",
              "      <td>老用户</td>\n",
              "      <td>否</td>\n",
              "      <td>...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>2.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>38</td>\n",
              "      <td>0</td>\n",
              "      <td>否</td>\n",
              "      <td>中价值</td>\n",
              "      <td>3日活跃用户</td>\n",
              "      <td>主流币_低频低杠杆用户</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1003380027</td>\n",
              "      <td>官网</td>\n",
              "      <td>官网</td>\n",
              "      <td>俄罗斯</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>36.0</td>\n",
              "      <td>老用户</td>\n",
              "      <td>否</td>\n",
              "      <td>...</td>\n",
              "      <td>11.0</td>\n",
              "      <td>2.0</td>\n",
              "      <td>39.0</td>\n",
              "      <td>38</td>\n",
              "      <td>0</td>\n",
              "      <td>否</td>\n",
              "      <td>中价值</td>\n",
              "      <td>3日活跃用户</td>\n",
              "      <td>长尾币_高频高杠杆用户</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>1004534556</td>\n",
              "      <td>Group AF</td>\n",
              "      <td>BD Abdallah</td>\n",
              "      <td>尼日利亚</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>老用户</td>\n",
              "      <td>是</td>\n",
              "      <td>...</td>\n",
              "      <td>1.0</td>\n",
              "      <td>2.0</td>\n",
              "      <td>83.0</td>\n",
              "      <td>93</td>\n",
              "      <td>0</td>\n",
              "      <td>否</td>\n",
              "      <td>中价值</td>\n",
              "      <td>3日活跃用户</td>\n",
              "      <td>BTC_ETH_低频高杠杆用户</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>1006541013</td>\n",
              "      <td>Group MN</td>\n",
              "      <td>BD Jacob Kasperek</td>\n",
              "      <td>波兰</td>\n",
              "      <td>3</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>221.0</td>\n",
              "      <td>老用户</td>\n",
              "      <td>是</td>\n",
              "      <td>...</td>\n",
              "      <td>45.0</td>\n",
              "      <td>5.0</td>\n",
              "      <td>76.0</td>\n",
              "      <td>86</td>\n",
              "      <td>392</td>\n",
              "      <td>否</td>\n",
              "      <td>高价值</td>\n",
              "      <td>3日活跃用户</td>\n",
              "      <td>长尾币_高频高杠杆用户</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>1007262247</td>\n",
              "      <td>Group MN</td>\n",
              "      <td>BD Abdulla2</td>\n",
              "      <td>墨西哥</td>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>977.0</td>\n",
              "      <td>新用户</td>\n",
              "      <td>否</td>\n",
              "      <td>...</td>\n",
              "      <td>26.0</td>\n",
              "      <td>18.0</td>\n",
              "      <td>26.0</td>\n",
              "      <td>35</td>\n",
              "      <td>0</td>\n",
              "      <td>否</td>\n",
              "      <td>高价值</td>\n",
              "      <td>3日活跃用户</td>\n",
              "      <td>BTC_ETH_高频高杠杆用户</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>5 rows × 30 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "      user_id   partner              staff nationality  VIP_level  spot_level  \\\n",
              "0  1003380027        官网                 官网         俄罗斯          0           0   \n",
              "1  1003380027        官网                 官网         俄罗斯          0           0   \n",
              "2  1004534556  Group AF        BD Abdallah        尼日利亚          0           0   \n",
              "3  1006541013  Group MN  BD Jacob Kasperek          波兰          3           0   \n",
              "4  1007262247  Group MN        BD Abdulla2         墨西哥          2           0   \n",
              "\n",
              "   asset_level  昨日账户余额 新老用户 是否kyc  ...  筛选交易日前7日日均交易笔数  筛选交易日前7日每笔持仓时间  \\\n",
              "0            0    36.0  老用户     否  ...             0.0             2.0   \n",
              "1            0    36.0  老用户     否  ...            11.0             2.0   \n",
              "2            0     0.0  老用户     是  ...             1.0             2.0   \n",
              "3            0   221.0  老用户     是  ...            45.0             5.0   \n",
              "4            0   977.0  新用户     否  ...            26.0            18.0   \n",
              "\n",
              "   筛选交易日前7日平均杠杆倍数 过去30天平均杠杆值  当日净充提金额  是否意向流失  用户分层  用户活跃等级         user_tag  \\\n",
              "0             0.0         38        0       否   中价值  3日活跃用户      主流币_低频低杠杆用户   \n",
              "1            39.0         38        0       否   中价值  3日活跃用户      长尾币_高频高杠杆用户   \n",
              "2            83.0         93        0       否   中价值  3日活跃用户  BTC_ETH_低频高杠杆用户   \n",
              "3            76.0         86      392       否   高价值  3日活跃用户      长尾币_高频高杠杆用户   \n",
              "4            26.0         35        0       否   高价值  3日活跃用户  BTC_ETH_高频高杠杆用户   \n",
              "\n",
              "   总体验金使用  \n",
              "0       0  \n",
              "1       0  \n",
              "2       0  \n",
              "3       1  \n",
              "4       0  \n",
              "\n",
              "[5 rows x 30 columns]"
            ]
          },
          "execution_count": 5,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Load the dataset - try multiple locations\n",
        "# Option 1: Check if dataset.xlsx exists in current directory\n",
        "if Path('dataset.xlsx').exists():\n",
        "    data_file = Path('dataset.xlsx')\n",
        "    print(f\"Loading data from: {data_file}\")\n",
        "    df = pd.read_excel(data_file)\n",
        "# Option 2: Check dataset folder\n",
        "elif Path('dataset').exists() and Path('dataset').is_dir():\n",
        "    dataset_folder = Path('dataset')\n",
        "    excel_files = list(dataset_folder.glob('*.xlsx')) + list(dataset_folder.glob('*.xls'))\n",
        "    if excel_files:\n",
        "        data_file = excel_files[0]\n",
        "        print(f\"Loading data from: {data_file}\")\n",
        "        df = pd.read_excel(data_file)\n",
        "    else:\n",
        "        raise FileNotFoundError(\"No Excel files found in 'dataset' folder.\")\n",
        "else:\n",
        "    raise FileNotFoundError(\n",
        "        \"Dataset not found. Please ensure:\\n\"\n",
        "        \"  1. dataset.xlsx is in the current directory, OR\\n\"\n",
        "        \"  2. Excel file(s) are in a 'dataset' folder\"\n",
        "    )\n",
        "\n",
        "print(f\"\\nDataset shape: {df.shape}\")\n",
        "print(f\"\\nColumn names: {df.columns.tolist()}\")\n",
        "print(f\"\\nFirst few rows:\")\n",
        "df.head()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Step 3: Define Column Groups and Preprocessing Pipeline"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Target distribution:\n",
            "总体验金使用\n",
            "1    5727\n",
            "0    2858\n",
            "Name: count, dtype: int64\n",
            "\n",
            "Target value counts (normalized):\n",
            "总体验金使用\n",
            "1    0.667094\n",
            "0    0.332906\n",
            "Name: proportion, dtype: float64\n",
            "\n",
            "Numerical columns to fill with 0: 15\n",
            "Categorical columns to fill with 0: 3\n",
            "Categorical columns to fill with '未持仓用户': 1\n",
            "Columns for target encoding: 10\n"
          ]
        }
      ],
      "source": [
        "# Define column groups for preprocessing\n",
        "target_column = '总体验金使用'\n",
        "\n",
        "# Numerical columns to fill with 0\n",
        "numerical_fill_zero = [\n",
        "    '昨日账户余额', 'ARPU30', 'ARPU7', 'ARPU14',\n",
        "    '当日合约交易量', '当日合约交易笔数', '当日充值金额',\n",
        "    '总合约交易量', '总体验金发放', '合约交易频率',\n",
        "    '筛选交易日前7日日均交易笔数', '筛选交易日前7日每笔持仓时间', \n",
        "    '筛选交易日前7日平均杠杆倍数', '过去30天平均杠杆值', '当日净充提金额'\n",
        "]\n",
        "\n",
        "# Categorical columns to fill with 0\n",
        "categorical_fill_zero = ['VIP_level', 'spot_level', 'asset_level']\n",
        "\n",
        "# Categorical columns to fill with \"未持仓用户\"\n",
        "categorical_fill_string = ['user_tag']\n",
        "\n",
        "# Columns for target encoding\n",
        "target_encode_columns = [\n",
        "    'partner', 'staff', 'nationality', '新老用户',\n",
        "    '是否kyc', '是否为混合交易用户', '是否意向流失',\n",
        "    '用户分层', '用户活跃等级', 'user_tag'\n",
        "]\n",
        "\n",
        "# Extract target variable\n",
        "if target_column not in df.columns:\n",
        "    raise ValueError(f\"Target column '{target_column}' not found in dataset\")\n",
        "\n",
        "target = df[target_column].copy()\n",
        "print(f\"Target distribution:\\n{target.value_counts()}\")\n",
        "print(f\"\\nTarget value counts (normalized):\\n{target.value_counts(normalize=True)}\")\n",
        "\n",
        "# Filter to only columns that exist in the dataset\n",
        "numerical_fill_zero = [col for col in numerical_fill_zero if col in df.columns]\n",
        "categorical_fill_zero = [col for col in categorical_fill_zero if col in df.columns]\n",
        "categorical_fill_string = [col for col in categorical_fill_string if col in df.columns]\n",
        "target_encode_columns = [col for col in target_encode_columns if col in df.columns]\n",
        "\n",
        "print(f\"\\nNumerical columns to fill with 0: {len(numerical_fill_zero)}\")\n",
        "print(f\"Categorical columns to fill with 0: {len(categorical_fill_zero)}\")\n",
        "print(f\"Categorical columns to fill with '未持仓用户': {len(categorical_fill_string)}\")\n",
        "print(f\"Columns for target encoding: {len(target_encode_columns)}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Feature columns: ['partner', 'staff', 'nationality', 'VIP_level', 'spot_level', 'asset_level', '昨日账户余额', '新老用户', '是否kyc', 'ARPU30', 'ARPU7', 'ARPU14', '是否为混合交易用户', '当日合约交易量', '当日合约交易笔数', '当日充值金额', '总合约交易量', '总体验金发放', '合约交易频率', '筛选交易日前7日日均交易笔数', '筛选交易日前7日每笔持仓时间', '筛选交易日前7日平均杠杆倍数', '过去30天平均杠杆值', '当日净充提金额', '是否意向流失', '用户分层', '用户活跃等级', 'user_tag']\n",
            "\n",
            "Feature shape: (8585, 28)\n",
            "Target shape: (8585,)\n"
          ]
        }
      ],
      "source": [
        "# Prepare features (remove user_id and target)\n",
        "features_df = df.drop(columns=[target_column], errors='ignore')\n",
        "if 'user_id' in features_df.columns:\n",
        "    # Keep user_id for later but remove from features\n",
        "    user_ids = features_df['user_id'].copy()\n",
        "    features_df = features_df.drop(columns=['user_id'])\n",
        "else:\n",
        "    user_ids = None\n",
        "\n",
        "print(f\"Feature columns: {features_df.columns.tolist()}\")\n",
        "print(f\"\\nFeature shape: {features_df.shape}\")\n",
        "print(f\"Target shape: {target.shape}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Preprocessing pipeline created with ColumnTransformer\n",
            "Number of transformers: 3\n"
          ]
        }
      ],
      "source": [
        "# Build the preprocessing pipeline using ColumnTransformer\n",
        "transformers = []\n",
        "\n",
        "# Numerical imputation (fill with 0)\n",
        "if numerical_fill_zero:\n",
        "    transformers.append(('num_imputer', NumericalImputer(fill_value=0), numerical_fill_zero))\n",
        "\n",
        "# Categorical imputation (fill with 0)\n",
        "if categorical_fill_zero:\n",
        "    transformers.append(('cat_imputer_zero', CategoricalImputer(fill_value=0), categorical_fill_zero))\n",
        "\n",
        "# String imputation (fill with \"未持仓用户\")\n",
        "if categorical_fill_string:\n",
        "    transformers.append(('cat_imputer_string', StringImputer(fill_value='未持仓用户'), categorical_fill_string))\n",
        "\n",
        "# Target encoding columns (will be handled separately in the pipeline)\n",
        "# We'll apply target encoding after initial imputation\n",
        "\n",
        "# Create ColumnTransformer for initial imputation\n",
        "preprocessor = ColumnTransformer(\n",
        "    transformers=transformers,\n",
        "    remainder='passthrough',  # Keep other columns as-is\n",
        "    verbose_feature_names_out=False\n",
        ")\n",
        "\n",
        "print(\"Preprocessing pipeline created with ColumnTransformer\")\n",
        "print(f\"Number of transformers: {len(transformers)}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Preprocessing pipeline ready for CompletePipeline\n"
          ]
        }
      ],
      "source": [
        "# The CompletePipeline class (imported from custom_transformers) will handle:\n",
        "# 1. Initial preprocessing (imputation) via ColumnTransformer\n",
        "# 2. Target encoding (requires y during fit)\n",
        "# 3. Model training\n",
        "# 4. Predictions with custom threshold\n",
        "\n",
        "print(\"Preprocessing pipeline ready for CompletePipeline\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "CompletePipeline class available from custom_transformers\n"
          ]
        }
      ],
      "source": [
        "# CompletePipeline is imported from custom_transformers\n",
        "# It handles all preprocessing and target encoding automatically\n",
        "print(\"CompletePipeline class available from custom_transformers\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Step 4: Split Data (Train, Validation, Test)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Training set: 5494 samples\n",
            "Validation set: 1374 samples\n",
            "Test set: 1717 samples\n"
          ]
        }
      ],
      "source": [
        "# Split data before building pipeline (to avoid data leakage)\n",
        "# First split: Train+Val (80%) and Test (20%)\n",
        "X_temp, X_test, y_temp, y_test = train_test_split(\n",
        "    features_df, target, test_size=0.2, random_state=42, stratify=target\n",
        ")\n",
        "\n",
        "# Second split: Train (64%) and Validation (16%)\n",
        "X_train, X_val, y_train, y_val = train_test_split(\n",
        "    X_temp, y_temp, test_size=0.2, random_state=42, stratify=y_temp\n",
        ")\n",
        "\n",
        "print(f\"Training set: {X_train.shape[0]} samples\")\n",
        "print(f\"Validation set: {X_val.shape[0]} samples\")\n",
        "print(f\"Test set: {X_test.shape[0]} samples\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Step 5: Build and Train Complete Pipeline"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Fitting complete pipeline on training data...\n",
            "Pipeline fitted successfully!\n"
          ]
        }
      ],
      "source": [
        "# Build the complete pipeline\n",
        "model = LogisticRegression(random_state=42, max_iter=1000, class_weight='balanced')\n",
        "complete_pipeline = CompletePipeline(\n",
        "    preprocessor=preprocessor,\n",
        "    target_encode_columns=target_encode_columns,\n",
        "    model=model,\n",
        "    threshold=0.6\n",
        ")\n",
        "\n",
        "# Fit the pipeline on training data\n",
        "print(\"Fitting complete pipeline on training data...\")\n",
        "complete_pipeline.fit(X_train, y_train)\n",
        "print(\"Pipeline fitted successfully!\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Step 6: Evaluation with Custom Threshold (0.6)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {},
      "outputs": [],
      "source": [
        "def evaluate_with_threshold(pipeline, X, y, threshold=0.6):\n",
        "    \"\"\"\n",
        "    Evaluate pipeline with custom probability threshold.\n",
        "    If probability > threshold, predict 1, otherwise 0.\n",
        "    \"\"\"\n",
        "    # Get probabilities\n",
        "    y_proba = pipeline.predict_proba(X)[:, 1]\n",
        "    \n",
        "    # Apply custom threshold\n",
        "    y_pred = (y_proba > threshold).astype(int)\n",
        "    \n",
        "    # Calculate metrics\n",
        "    accuracy = accuracy_score(y, y_pred)\n",
        "    f1 = f1_score(y, y_pred)\n",
        "    roc_auc = roc_auc_score(y, y_proba)\n",
        "    \n",
        "    return accuracy, f1, roc_auc, y_pred, y_proba"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "=== Training Set Results ===\n",
            "Accuracy: 0.8759\n",
            "F1-Score: 0.8996\n",
            "ROC-AUC Score: 0.9445\n"
          ]
        }
      ],
      "source": [
        "# Evaluate on Training set\n",
        "train_acc, train_f1, train_roc, train_pred, train_proba = evaluate_with_threshold(\n",
        "    complete_pipeline, X_train, y_train, threshold=0.6\n",
        ")\n",
        "\n",
        "print(\"=== Training Set Results ===\")\n",
        "print(f\"Accuracy: {train_acc:.4f}\")\n",
        "print(f\"F1-Score: {train_f1:.4f}\")\n",
        "print(f\"ROC-AUC Score: {train_roc:.4f}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Step 7: Evaluate on Validation and Test Sets"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "=== Validation Set Results ===\n",
            "Accuracy: 0.8566\n",
            "F1-Score: 0.8821\n",
            "ROC-AUC Score: 0.9379\n"
          ]
        }
      ],
      "source": [
        "# Evaluate on Validation set\n",
        "val_acc, val_f1, val_roc, val_pred, val_proba = evaluate_with_threshold(\n",
        "    complete_pipeline, X_val, y_val, threshold=0.6\n",
        ")\n",
        "\n",
        "print(\"=== Validation Set Results ===\")\n",
        "print(f\"Accuracy: {val_acc:.4f}\")\n",
        "print(f\"F1-Score: {val_f1:.4f}\")\n",
        "print(f\"ROC-AUC Score: {val_roc:.4f}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "=== Test Set Results ===\n",
            "Accuracy: 0.8736\n",
            "F1-Score: 0.8977\n",
            "ROC-AUC Score: 0.9441\n"
          ]
        }
      ],
      "source": [
        "# Evaluate on Test set\n",
        "test_acc, test_f1, test_roc, test_pred, test_proba = evaluate_with_threshold(\n",
        "    complete_pipeline, X_test, y_test, threshold=0.6\n",
        ")\n",
        "\n",
        "print(\"=== Test Set Results ===\")\n",
        "print(f\"Accuracy: {test_acc:.4f}\")\n",
        "print(f\"F1-Score: {test_f1:.4f}\")\n",
        "print(f\"ROC-AUC Score: {test_roc:.4f}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Step 8: Save Complete Pipeline"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Complete pipeline saved as 'trial_fund_model.joblib'\n",
            "\n",
            "Pipeline includes:\n",
            "- Numerical imputation (fill with 0)\n",
            "- Categorical imputation (fill with 0 for VIP_level, spot_level, asset_level)\n",
            "- String imputation (fill with '未持仓用户' for user_tag)\n",
            "- Target encoding for categorical features\n",
            "- Logistic Regression model\n",
            "- Custom threshold (0.6) for predictions\n"
          ]
        }
      ],
      "source": [
        "# Save the complete pipeline\n",
        "# The CompletePipeline object contains everything needed for inference\n",
        "joblib.dump(complete_pipeline, 'trial_fund_model.joblib')\n",
        "print(\"Complete pipeline saved as 'trial_fund_model.joblib'\")\n",
        "print(\"\\nPipeline includes:\")\n",
        "print(\"- Numerical imputation (fill with 0)\")\n",
        "print(\"- Categorical imputation (fill with 0 for VIP_level, spot_level, asset_level)\")\n",
        "print(\"- String imputation (fill with '未持仓用户' for user_tag)\")\n",
        "print(\"- Target encoding for categorical features\")\n",
        "print(\"- Logistic Regression model\")\n",
        "print(\"- Custom threshold (0.6) for predictions\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Summary\n",
        "\n",
        "The model has been trained and saved. The preprocessing pipeline includes:\n",
        "- Target encoding for categorical variables\n",
        "- Imputation rules for missing values\n",
        "- Logistic Regression model\n",
        "- Custom threshold (0.6) for predictions\n",
        "\n",
        "Use the inference script to make predictions on new Excel files."
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.14.2"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}
